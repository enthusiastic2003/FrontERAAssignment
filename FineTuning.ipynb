{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 00:29:32.876464: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-23 00:29:32.884225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-23 00:29:32.895249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-23 00:29:32.895268: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-23 00:29:32.902725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-23 00:29:33.311137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from a csv file\n",
    "\n",
    "csv_file = \"dataClassified/data.csv\"\n",
    "\n",
    "# csv is in format: filename, label\n",
    "\n",
    "prepend_path = \"dataClassified/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 00:29:37.300166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-23 00:29:37.326830: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Load datasets from util.Dataset\n",
    "\n",
    "dataset_train = util.CustomDataset(csv_file, prepend_path, \"train\")\n",
    "dataset_val = util.CustomDataset(csv_file, prepend_path, \"val\")\n",
    "dataset_test = util.CustomDataset(csv_file, prepend_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finetuning_utils as ftu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 00:30:09.771917: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "embeds, labels = ftu.preprocess_dataset(dataset_train, yamnet_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 00:30:15.316946: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "embeds_val, labels_val = ftu.preprocess_dataset(dataset_val, yamnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 00:30:18.767384: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "embeds_test, labels_test = ftu.preprocess_dataset(dataset_test, yamnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(1024,)),  # YAMNet embeddings are 1024-dimensional\n",
    "    layers.Dense(512, activation='relu'),\n",
    "\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(util.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Optimizer: Adam with tuned learning rate\n",
    "optimizer = Adam(learning_rate=1e-4 , weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Training fold 1/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.6094 - val_accuracy: 0.7690 - val_loss: 0.5490 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8112 - loss: 0.4722 - val_accuracy: 0.7811 - val_loss: 0.5382 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8211 - loss: 0.4440 - val_accuracy: 0.7701 - val_loss: 0.5587 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4196 - val_accuracy: 0.7793 - val_loss: 0.5482 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.3857 - val_accuracy: 0.7768 - val_loss: 0.5531 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8573 - loss: 0.3646 - val_accuracy: 0.7784 - val_loss: 0.5576 - learning_rate: 5.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3506 - val_accuracy: 0.7733 - val_loss: 0.5744 - learning_rate: 5.0000e-05\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n",
      "✅ Fold 1 Validation Accuracy: 0.7811\n",
      "\n",
      "🔄 Training fold 2/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.4358 - val_accuracy: 0.7778 - val_loss: 0.5381 - learning_rate: 5.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4255 - val_accuracy: 0.7813 - val_loss: 0.5386 - learning_rate: 5.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.4145 - val_accuracy: 0.7752 - val_loss: 0.5418 - learning_rate: 5.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.4031 - val_accuracy: 0.7836 - val_loss: 0.5393 - learning_rate: 5.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8498 - loss: 0.3818 - val_accuracy: 0.7823 - val_loss: 0.5434 - learning_rate: 2.5000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.3765 - val_accuracy: 0.7811 - val_loss: 0.5441 - learning_rate: 2.5000e-05\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n",
      "✅ Fold 2 Validation Accuracy: 0.7778\n",
      "\n",
      "🔄 Training fold 3/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4218 - val_accuracy: 0.7772 - val_loss: 0.5406 - learning_rate: 2.5000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8305 - loss: 0.4171 - val_accuracy: 0.7799 - val_loss: 0.5365 - learning_rate: 2.5000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4085 - val_accuracy: 0.7831 - val_loss: 0.5346 - learning_rate: 2.5000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4072 - val_accuracy: 0.7799 - val_loss: 0.5390 - learning_rate: 2.5000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.4024 - val_accuracy: 0.7819 - val_loss: 0.5374 - learning_rate: 2.5000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3905 - val_accuracy: 0.7791 - val_loss: 0.5506 - learning_rate: 2.5000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8466 - loss: 0.3822 - val_accuracy: 0.7801 - val_loss: 0.5451 - learning_rate: 1.2500e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8476 - loss: 0.3809 - val_accuracy: 0.7817 - val_loss: 0.5440 - learning_rate: 1.2500e-05\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "✅ Fold 3 Validation Accuracy: 0.7831\n",
      "\n",
      "🔄 Training fold 4/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.4080 - val_accuracy: 0.7776 - val_loss: 0.5410 - learning_rate: 1.2500e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4062 - val_accuracy: 0.7813 - val_loss: 0.5407 - learning_rate: 1.2500e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4036 - val_accuracy: 0.7788 - val_loss: 0.5401 - learning_rate: 1.2500e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3914 - val_accuracy: 0.7801 - val_loss: 0.5415 - learning_rate: 1.2500e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3934 - val_accuracy: 0.7793 - val_loss: 0.5486 - learning_rate: 1.2500e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8486 - loss: 0.3867 - val_accuracy: 0.7819 - val_loss: 0.5421 - learning_rate: 1.2500e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8498 - loss: 0.3818 - val_accuracy: 0.7819 - val_loss: 0.5430 - learning_rate: 6.2500e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3794 - val_accuracy: 0.7803 - val_loss: 0.5475 - learning_rate: 6.2500e-06\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step\n",
      "✅ Fold 4 Validation Accuracy: 0.7788\n",
      "\n",
      "🔄 Training fold 5/5...\n",
      "Epoch 1/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3998 - val_accuracy: 0.7840 - val_loss: 0.5394 - learning_rate: 6.2500e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3982 - val_accuracy: 0.7817 - val_loss: 0.5413 - learning_rate: 6.2500e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3956 - val_accuracy: 0.7809 - val_loss: 0.5447 - learning_rate: 6.2500e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3934 - val_accuracy: 0.7815 - val_loss: 0.5444 - learning_rate: 6.2500e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.3898 - val_accuracy: 0.7805 - val_loss: 0.5411 - learning_rate: 3.1250e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3954 - val_accuracy: 0.7809 - val_loss: 0.5433 - learning_rate: 3.1250e-06\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step\n",
      "✅ Fold 5 Validation Accuracy: 0.7840\n",
      "\n",
      "🎯 Final Validation Accuracy (across folds): 0.7809 ± 0.0024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "k_folds = 5\n",
    "\n",
    "# Prepare KFold splitter\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store fold results\n",
    "fold_accuracies = []\n",
    "\n",
    "# Convert labels to numpy if not already\n",
    "labels_np = np.array(labels)\n",
    "embeds_np = np.array(embeds)\n",
    "\n",
    "# K-Fold Cross Validation (using separate validation set)\n",
    "for fold, (train_idx, _) in enumerate(kf.split(embeds_np)):\n",
    "    print(f\"\\n🔄 Training fold {fold + 1}/{k_folds}...\")\n",
    "\n",
    "    # Split data for training (validation is separate)\n",
    "    X_train, y_train = embeds_np[train_idx], labels_np[train_idx]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(embeds_val, labels_val),  # Dedicated validation set\n",
    "                        epochs=50,\n",
    "                        batch_size=32,\n",
    "                        callbacks=[early_stop, reduce_lr],\n",
    "                        verbose=1,\n",
    "    )\n",
    "    #                    class_weight=class_weights)\n",
    "\n",
    "    # Evaluate on the dedicated validation set\n",
    "    val_preds = model.predict(embeds_val)\n",
    "    val_preds_classes = np.argmax(val_preds, axis=1)\n",
    "    val_accuracy = accuracy_score(labels_val, val_preds_classes)\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    print(f\"✅ Fold {fold + 1} Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Final Cross-Validation Result\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f\"\\n🎯 Final Validation Accuracy (across folds): {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Check if tensorflow is using GPU\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 - 0s - 748us/step - accuracy: 0.8356 - loss: 0.4504\n",
      "\n",
      "Test accuracy: 0.8355674743652344\n"
     ]
    }
   ],
   "source": [
    "# Check the model performance on the test set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(embeds_test, labels_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FrontEra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
